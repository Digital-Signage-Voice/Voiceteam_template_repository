# main_pipeline.py (v2 - Updated by Haechan)
# ì—­í• : ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì´ê´„í•˜ë©°, ê° íŒ€ì›ì˜ 'ì™„ì„±ëœ ëª¨ë“ˆ'ì„ ê°€ì ¸ì™€ ì¡°ë¦½í•˜ëŠ” ì§€íœ˜ì

import cv2
import numpy as np
from moviepy.editor import VideoFileClip
import soundfile as sf

# --- ëª¨ë“ˆ í†µí•© ì§€ì  ---
# í˜„ì§€ë‹˜ì˜ 'ì˜ìƒ ì²˜ë¦¬ ì—”ì§„' í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
# (ì´ì œ video_module.py ëŒ€ì‹ , í˜„ì§€ë‹˜ì´ ë§Œë“  processor.pyë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤)
from src.video.processor import VideoProcessor

# ì›í›„ë‹˜ì˜ 'ìŒì„± ì²˜ë¦¬ ì—”ì§„' í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. (ê¸°ì¡´ê³¼ ë™ì¼)
from src.audio.audio_module import denoise_audio


def run_voice_team_pipeline(input_video_path: str, output_audio_path: str):
    """
    ìš°ë¦¬ VoiceíŒ€ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    print("ğŸš€ VoiceíŒ€ ì „ì²´ íŒŒì´í”„ë¼ì¸ v2ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤!")

    # --- 1ë‹¨ê³„: ëª¨ë“ˆ ì¤€ë¹„ ---
    # í˜„ì§€ë‹˜ì˜ ì˜ìƒ ì²˜ë¦¬ ì—”ì§„ì„ ìƒì„±í•©ë‹ˆë‹¤. (ì˜¤í”„ë¼ì¸ ì˜ìƒ íŒŒì¼ ëª¨ë“œ)
    print("ğŸ› ï¸  1ë‹¨ê³„: í˜„ì§€ë‹˜ì˜ ì˜ìƒ ì²˜ë¦¬ ì—”ì§„ì„ ì¤€ë¹„í•©ë‹ˆë‹¤...")
    # source='video'ë¡œ ì„¤ì •í•˜ì—¬ íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë™í•˜ê²Œ í•©ë‹ˆë‹¤.
    video_processor = VideoProcessor(source='video', path=input_video_path, visualize=False)

    # --- 2ë‹¨ê³„: ì¬ë£Œ ì¤€ë¹„ ---
    print("ğŸ”ª 2ë‹¨ê³„: ë™ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤...")
    video_clip = VideoFileClip(input_video_path)
    full_audio_data = video_clip.audio.to_soundarray()
    sample_rate = video_clip.audio.fps
    final_audio_data = full_audio_data.copy()

    # --- 3ë‹¨ê³„: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (í”„ë ˆì„ ë‹¨ìœ„ ì²˜ë¦¬) ---
    print("\nğŸ”„ 3ë‹¨ê³„: ì˜ìƒì˜ ê° í”„ë ˆì„ì„ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬í•˜ë©° íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤...")
    
    # ë™ì˜ìƒ íŒŒì¼ì„ í•œ í”„ë ˆì„ì”© ì½ê¸° ìœ„í•´ OpenCVë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    cap = cv2.VideoCapture(input_video_path)
    frame_id = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # âœ¨ í•µì‹¬ í†µí•© ì§€ì  âœ¨
        # í˜„ì¬ í”„ë ˆì„ì„ í˜„ì§€ë‹˜ì˜ ì—”ì§„ì— ë„£ê³ , ë¶„ì„ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°›ìŠµë‹ˆë‹¤.
        result_dict = video_processor.process_frame(frame_id, frame)
        
        is_speaking = result_dict['is_speaking']
        timestamp = result_dict['timestamp']

        print(f"  - Frame #{frame_id}: í˜„ì¬ ì‹œê°„ {timestamp:.2f}ì´ˆ, ë°œí™” ì—¬ë¶€: {is_speaking}")

        # ë§Œì•½ 'ë°œí™” ì¤‘' ì´ë¼ë©´, í•´ë‹¹ ì‹œê°„ëŒ€ì˜ ì˜¤ë””ì˜¤ì— ì›í›„ë‹˜ì˜ ëª¨ë“ˆì„ ì ìš©
        # (ì´ ë¶€ë¶„ì€ ì¶”í›„ ì›í›„ë‹˜ ëª¨ë“ˆì´ ì‹¤ì‹œê°„ ì²­í¬ ë‹¨ìœ„ë¥¼ ì§€ì›í•˜ë©´ ë” ì •êµí™”ë  ì˜ˆì •)
        # ì§€ê¸ˆì€ ê°„ë‹¨íˆ 'speech_segments' ì •ë³´ë¥¼ í™œìš©
        if result_dict['speech_segments']:
             for segment in result_dict['speech_segments']:
                start_time = segment.get('start')
                # 'end'ëŠ” ì•„ì§ ì—†ìœ¼ë¯€ë¡œ, ì§€ê¸ˆì€ ì´ ë¡œì§ì„ ë‹¨ìˆœí™”í•˜ì—¬ ì ìš©
                # ì´ ë¶€ë¶„ì€ ì•ìœ¼ë¡œ ì›í›„ë‹˜ê³¼ í•¨ê»˜ ë” ë°œì „ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.

        frame_id += 1
    
    cap.release()
    print("\nâœ… ì˜ìƒì˜ ëª¨ë“  í”„ë ˆì„ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    # (ì„ì‹œ) í˜„ì¬ëŠ” ì˜¤í”„ë¼ì¸ ë°©ì‹ì´ë¯€ë¡œ, ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í›„ì²˜ë¦¬í•˜ëŠ” ë¡œì§ì´ í•„ìš”
    # ì´ ë¶€ë¶„ì€ ì¶”í›„ ì‹¤ì‹œê°„ êµ¬ì¡°ë¡œ ë³€ê²½ë˜ë©´ì„œ ìˆ˜ì •ë  ê²ƒì…ë‹ˆë‹¤.
    # ì§€ê¸ˆì€ ì›í›„ë‹˜ ëª¨ë“ˆì„ í˜¸ì¶œí•˜ëŠ” ë¶€ë¶„ì„ ë¹„ì›Œë‘ê³ , íŒŒì´í”„ë¼ì¸ì´ ì—°ê²°ë˜ëŠ” ê²ƒë§Œ í™•ì¸í•©ë‹ˆë‹¤.

    # --- 4ë‹¨ê³„: ìµœì¢… ê²°ê³¼ë¬¼ ì €ì¥ ---
    print("\nğŸ’¾ 4ë‹¨ê³„: ìµœì¢… ì˜¤ë””ì˜¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤...")
    # sf.write(output_audio_path, final_audio_data, sample_rate) # ì•„ì§ ì‹¤ì œ ì²˜ë¦¬ê°€ ì—†ìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬
    print(f"ğŸ‰ ì„±ê³µ! íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (ê²½ë¡œ: '{output_audio_path}')")


# --- ì´ íŒŒì¼ì„ ì§ì ‘ ì‹¤í–‰í–ˆì„ ë•Œë§Œ ì•„ë˜ ì½”ë“œê°€ ë™ì‘í•©ë‹ˆë‹¤ ---
if __name__ == "__main__":
    test_video = "data/input/your_test_video.mp4"  # ì‹¤ì œ í…ŒìŠ¤íŠ¸í•  ì˜ìƒ íŒŒì¼ ê²½ë¡œë¥¼ ë„£ì–´ì£¼ì„¸ìš”.
    output_wav = "data/output/final_clean_audio.wav"

    run_voice_team_pipeline(test_video, output_wav)